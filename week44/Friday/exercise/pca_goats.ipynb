{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Computer lab: Principal Component Analysis (PCA) on goat SNP data\n",
    "\n",
    "This exercise is build around a dataset from Colli et al. Genet Sel Evol (2018) 50:58 https://doi.org/10.1186/s12711-018-0422-x and lecture notes from Genomics Boot Camp, an online course by Gábor Mészáros.\n",
    "\n",
    "### Population Structure within Goats\n",
    "\n",
    "Today we will do a principal component analysis (PCA) based on quality-controlled genotype data. And as you probably guessed from the title we will look a goat data today. But before jumping into the exciting world of goats. Let's look at the PCA in general, but try to keep it on a high level of abstraction (read; let's try to avoid the math for now).\n",
    "\n",
    "### The Principal Component Analysis\n",
    "\n",
    "Principal Component Analysis (PCA) is a powerful statistical technique employed in population genetics to unravel genetic variation within and among populations. By reducing the complexity of genetic data into a few orthogonal axes, named Principal Components. These axes are then ordered by the amounts of variation explained by that linear combination of variables. The math behind it are, I geuss a bit beyond the scope of this course, but it will be covered in Statistical and Machine Learning in Bioinformatics in the spring.\n",
    "\n",
    "### The Goats\n",
    "\n",
    "The PCA itself is a way to visualize complex systems in a simple way. In our case, we want to show relationships between the worldwide goat populations genotyped in the ADAPTmap project. After the quality control, we have 4532 animals left. If we compute genetic distances (with PLINK), we get a matrix of 4532 by 4532 animals, with more than 10 million pairwise combinations. So a \"rather\" long list to scroll through, let alone make sense of it. Fortunately, we can apply some clever statistical methods to simplify it for us. We will lose some precision and nuances about the relationships between breeds, but in exchange, we can see everything in one figure.\n",
    "\n",
    "### The Packages\n",
    "You can again install all dependencies from the `env.yaml` file as follows:\n",
    "```bash\n",
    "mamba env create -f env.yaml\n",
    "```\n",
    "For those of you who have problems setting up the environment, the notebook is also hosted on [Google Colab](https://colab.research.google.com/drive/1ilgzhFTFvcDdseU2_BO53xiKp7YZVOts?usp=sharing).\n",
    "\n",
    "We start by downloading the data from the GitHub repository. The data is stored in a zip file, which we will download and unzip."
   ],
   "id": "f949c2cf2466943c"
  },
  {
   "cell_type": "code",
   "id": "de86047c3e8af195",
   "metadata": {},
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_file(url: str, dest: str):\n",
    "    \"\"\"\n",
    "    Download a file from a url and save it to a destination\n",
    "\n",
    "    :param url: URL to download from\n",
    "    :param dest: Destination to save the file to\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    with open(dest, 'wb') as f:\n",
    "        for chunk in tqdm(response.iter_content(chunk_size=8192), total=total_size / 8192,\n",
    "                          unit='MB', unit_scale=8192 / (1024 * 1024), desc=\"Downloading\"):\n",
    "            f.write(chunk)\n",
    "\n",
    "\n",
    "def unzip(zip_file: str):\n",
    "    \"\"\"\n",
    "    Unzip a file to a destination\n",
    "\n",
    "    :param zip_file: Path to the zip file\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "\n",
    "url = (\"https://github.com/Bjarke-M/Evolutionary_Thinking_2024/blob/\"\n",
    "       \"fb17582a10b81c6b8ef9641222eb012a69c227fb/week44/Friday/data.zip?raw=true\")\n",
    "\n",
    "dest = os.getcwd() + \"/goats.zip\"\n",
    "download_file(url, dest)\n",
    "unzip(dest)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### PLINK\n",
    "\n",
    "To process the data, we will use a program called PLINK, which is a free, open-source whole genome association analysis toolset, designed to perform a range of basic, large-scale analyses in a computationally efficient manner. You can read more about it here:\\[https://zzz.bwh.harvard.edu/plink/\\]. More precisely, we will use the Python wrapper for PLINK, called pandas-plink. pandas-plink is a Python library for reading PLINK files into native Python data structures using pandas and dask. You can read more about it here: \\[https://pandas-plink.readthedocs.io/en/latest/].\n",
    "\n",
    "We obtain three files: bed, bim, and fam."
   ],
   "id": "eedeb3c97bc9d3df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pandas_plink import read_plink\n",
    "\n",
    "(bim, fam, bed) = read_plink(os.getcwd() + \"/data/snps\")"
   ],
   "id": "fdafc640d8366cc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### BIM file\n",
    "The bim file contains information about the SNPs in the dataset, and is made available as a pandas DataFrame."
   ],
   "id": "475648269ca6240c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bim.head()",
   "id": "b5b91fa973b27b41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### FAM file\n",
    "The fam file contains information about the individuals in the dataset, and is also made available as a pandas DataFrame."
   ],
   "id": "c18568360532b042"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "fam.head()",
   "id": "c0f4ecb242b8f216",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### BED file\n",
    "The bed file contains the genotype data per SNP and individual which we will mainly work with. This file is potentially large, and made available as a dask array. Dask is a flexible library for parallel computing in Python. It allows you to break up arrays into smaller chunks, which can be computed in parallel. This is useful when working with large datasets that do not fit into memory. The interface is similar to NumPy, so you can use it as a drop-in replacement in many cases. Operations on dask arrays are lazy, meaning that they are not computed until you explicitly ask for the result. This allows you to build up complex computations without running out of memory. You can read more about it here: \\[https://docs.dask.org/en/stable/array.html]. We can evaluate the query by calling the compute() method, which will return a NumPy array."
   ],
   "id": "373f82bab615765e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get the first 5 rows (SNPs) and 5 columns (individuals) of the bed file\n",
    "bed[:5, :5].compute()"
   ],
   "id": "4073c7f907642e01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Quality control and filtering\n",
    "\n",
    "We first need to filter the data to remove SNPs and individuals with too many missing genotypes. We will also remove SNPs with a minor allele frequency (MAF) below 0.05. The filtering will be done with dask arrays."
   ],
   "id": "9a25cb962fcf736b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import dask.array as da\n",
    "\n",
    "# Drop mitochondrial and sex chromosome SNPs based on your data’s chromosome annotations\n",
    "# Filter chromosomes in bim DataFrame\n",
    "autosomal_snps = bim['chrom'].astype(int) <= 29\n",
    "bed_filtered = bed[autosomal_snps]"
   ],
   "id": "1ff11ccef802496e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Question: Why would we want to drop mitochondrial and sex chromosome SNPs?  ",
   "id": "8928d0e3e6d7ab2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter individuals (axis=1) with >5% missing SNPs\n",
    "bed_filtered = bed[:, da.isnan(bed).mean(axis=0) <= 0.05]\n",
    "\n",
    "# Filter SNPs (axis=0) with >5% missing genotypes\n",
    "bed_filtered = bed_filtered[da.isnan(bed_filtered).mean(axis=1) <= 0.05, :]"
   ],
   "id": "e2504069b0b25e0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Question: Why would we want to filter individuals with >5% missing SNPs and SNPs with >5% missing genotypes?",
   "id": "4fe69191ec8abcca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter SNPs with MAF < 0.05\n",
    "maf = da.nanmean(bed_filtered, axis=1) / 2\n",
    "bed_filtered = bed_filtered[(maf >= 0.05) & (maf <= 0.95), :]"
   ],
   "id": "3294b0710429cd9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Question: Why would we want to filter SNPs with MAF < 0.05? What is the MAF and why do we divide by 2 in the calculation?",
   "id": "d23b0477eb035ffb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# perform computation and obtain numpy array\n",
    "bed_filtered = bed_filtered.compute()"
   ],
   "id": "f2e6abe3699d1112",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before we can perform the PCA, we need to impute the missing values. We will use the mean value to fill in the missing values.",
   "id": "d5129214e6b8a867"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fit and transform the data to fill NaNs\n",
    "# You can change the strategy to 'median', 'most_frequent', or 'constant'\n",
    "bed_imputed = SimpleImputer(strategy='mean').fit_transform(bed_filtered)"
   ],
   "id": "76097ee4232fa09e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Question: Why would we want to impute the missing values before performing the PCA? What does strategy='mean' mean?",
   "id": "7389d21b301bdb7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)  # Number of components to keep\n",
    "pca_result = pca.fit_transform(bed_imputed.T)\n",
    "\n",
    "# Get explained variance\n",
    "explained_variance = pca.explained_variance_ratio_ * 100"
   ],
   "id": "5c939130920eb2c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now visualize the principal components in a scatter plots. We focus on the first two principal components, which explain the most variance in the data. We also show the percentage of variance explained by each component on the axes.",
   "id": "9ebc9f036fb60307"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot PCA\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)\n",
    "\n",
    "plt.title('PCA of SNP Data')\n",
    "plt.xlabel(f'PC1 ({explained_variance[0]:.2f}% variance explained)')\n",
    "plt.ylabel(f'PC2 ({explained_variance[1]:.2f}% variance explained)')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "7409a8a430c2da8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Question: What does each point in the scatter plot represent? What do the axes represent? What does the percentage of variance explained by each component mean?",
   "id": "a60ba7526db540ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Question: How does the explained variance compare to the paper? What could be the reasons for the differences?",
   "id": "7aaf0f4ad92c762e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Question: What evolutionary explanations causes populations structure? and Can you see an overall pattern to the goat populations?",
   "id": "eb4ba67ce3e56a96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Optional question: How does the population structure of the first two principal components and explained variance change if we apply more stringent missing value filtering or MAF filtering?",
   "id": "e68056ecec300364"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Optional question: How does the PCA change if we only consider mitochondrial and sex chromosome SNPs?",
   "id": "7d8e2f393fa5ce6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Optional question: What if we visualize the first vs. the third principal component instead of the first two? Compare with the paper.",
   "id": "76f619c56711b995"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Optional question: Does the PCA change for different imputation strategies?",
   "id": "6fcdfead1c6f4728"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Optional question: What is the minimum number of principal components needed to explain 50% of the total variance?",
   "id": "64d92a5de13bd9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Additional information: Because PCAs is such a fast and easy way to gain valuable insights, one should be careful with the interpretations based in PCAs alone: https://www.nature.com/articles/s41598-022-14395-4",
   "id": "704263539f9edc58"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
